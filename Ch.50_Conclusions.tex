

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %% CONCLUSIONS                               %%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Conclusions\label{conclusions}}
\begin{comment}
    
Guides:
    - As many pages as it takes (thesis max is around 20 pages)

TODO:
    [ ] How AI has augmented SE attacks and countermeasures
    [ ] Gap in the literature

What to cover:
    - How AI has augmented SE attacks and countermeasures
    - Gap in the literature regarding SE and AI intersection?
    - Analysis on where AI-powered SE attacks might be headed in the future
        - Also about robotics and human-like actors
    - What organizations and individuals need to do regarding the evolving landscape of SE attacks

Speculation:
    - Drones dropping USB thumbdrives?
    - Human-like android as threat actors
    - Impact of robotics on dumpster diving, shoulder surfing and baiting
    
Literature:
    - Gen and detection of deepfakes

From training material:
    - Yhteenveto vaatimattomimmillaan on vain lyhyt kertaus kirjoituksen keskeisistä asioista. Arvokkaamman yhteenvedon saa aikaan kommentoimalla työn tulosten arvoa, työn liittymistä ympäristöön ja tulevaisuudennäkymiä. Tällaiset arviot huolellisesti perusteltava.

\end{comment}


As we've seen, SE is still as much a threat as it has ever been, despite major efforts to the contrary.

What's certain is that we can count on AI developing, AI-based social engineering attacks evolving with it, and the need for continuous, innovative user training growing in the future. Attackers and defenders are playing a never-ending game of "cat \& mouse" where nobody can rest.

X in Y references that training users effects will wear off in 3 weeks, necessiting continous retraining approaches.

I'll end with the question that I started with; what, if anything, can the end-user trust anymore? And perhaps, with the advances in AI technology, the answer is "no-one".


%Modern AI can assist with the deployment of the pretext by being a sparring partner to the attacker, giving a safe "sandbox" to try out potential attacks and find ways in which the target might react.