

% --------------------------------
% CONCLUSIONS
% --------------------------------


\chapter{Conclusions\label{chapter:conclusions}}

\begin{comment}

Guides:
    - 1 to 3 pages max?

TODO:
    [ ] How AI has augmented SE attacks and countermeasures
    [ ] Gap in the literature

What to cover:
    - How AI has augmented SE attacks and countermeasures
    - Gap in the literature regarding SE and AI intersection?
    - Analysis on where AI-powered SE attacks might be headed in the future
        - Also about robotics and human-like actors
    - What organizations and individuals need to do regarding the evolving landscape of SE attacks

Speculation:
    - Drones dropping USB thumbdrives?
    - Human-like android as threat actors
    - Impact of robotics on dumpster diving, shoulder surfing and baiting
    
Literature:
    - Gen and detection of deepfakes

From training material:
    - "Yhteenveto vaatimattomimmillaan on vain lyhyt kertaus kirjoituksen keskeisistä asioista. Arvokkaamman yhteenvedon saa aikaan kommentoimalla työn tulosten arvoa, työn liittymistä ympäristöön ja tulevaisuudennäkymiä. Tällaiset arviot huolellisesti perusteltava."
    - "Yhteenvetoluku kuvaa teknisten johtopäätösten tuomaa impaktia"

\end{comment}

The subfield of social engineering within cybersecurity is undergoing a significant transformation with the advent of modern artificial intelligence (AI). This thesis explored how AI empowers malicious actors and also how current countermeasures need to be updated to reflect this evolving threat landscape.

%The subfield of cybersecurity called social engineering (SE) is undergoing a significant transformation with the advent of modern artificial intelligence (AI). This thesis explored how AI, such as any new technology within the IT sphere, can be used both by malicious actors as well as legitimate users.


%This thesis explored the dual-faceted nature of AI on SE, exploring both the enhanced capabilities it provides malicious actors and the countermeasures it provides to cybersecurity professionals, paying special attention to the human element of social engineering.

Modern AI is revolutionizing social engineering attacks, enabling attackers to use sophisticated tactics like automated spear phishing and voice phishing (vishing) with real-time voice morphing. These advancements reveal that traditional countermeasures are becoming ever more ineffective, requiring a re-evaluation of current strategies and tactics.

%AI has truly revolutionized the execution of a number of different social engineering attacks, allowing attackers to deploy highly sophisticated and targeted tactics, such as spear phishing and voice phishing (vishing) with real-time voice morphing. Because of this, traditional countermeasures are becoming ever more ineffective.

One of the most notable contributions of AI is its ability to automate and enhance deceptive practices. Machine learning facilitates the crafting of personalized phishing messages that closely mimic legitimate communications, while deepfake technologies alter or produce synthetic media that convincingly impersonate authentic images, audio and videos. Such advancements enable attackers to deceive targets more efficiently into disclosing sensitive information or taking actions that compromise security.

Where previously an employee could authenticate a caller by recognizing their voice, intonations, and accents \citep{mitnickArtDeceptionControlling2003}, today and especially in the near future this will not be enough. User training and awareness programs need to be updated for novel threat of AI in SE.

In their article, \cite{guptaFromChatGPTtoThreatGPT2023}, claim that "\textit{through continued efforts and cooperation among various stakeholders, it’s possible to prevent the misuse of AI systems and ensure their continued benefit to society}", but this can only be true if advanced AI systems remain in the hands of their developers and that they retract older versions of their AI systems from use, since the older versions have already been used by malicious actors. And since with social engineering an attacker can ask ChatGPT to roleplay a certain scenario that the attacker will later enact in a live call, misuse of AI systems can never be fully prevented. AI is a tool, and like any tool it can be used for its intended purpose or in ways the original manufacturer did not intend or would not want.

According to IBM's 2024 Cost of a Data Breach\footnote{https://www.ibm.com/reports/data-breach (accessed 2024-08-11)} report, organizations are increasingly leveraging AI and automation in their security operations, with 2/3's of studied organizations deploying these technologies. This presents a 10\% increase from last year. Notably, when AI was extensively deployed in prevention workflows, including attack surface management (ASM), red-teaming and posture management, these organizations saw an average reduction of \$2.2 million breach costs compared to the average of \$4,88 million, a 45\% reduction. IBM found a striking correlation, that the more an organization relied on AI, the lower their average breach costs were.

While AI can help detect social engineering attacks, it does not mitigate the need for user training and awareness programs. Quite the contrary, with AI-powered attacks, the need for awareness and vigilance will likely grow even higher.

What seems certain is that we can count on the rapid development of AI technologies, AI-based social engineering attacks evolving with them, and the need for continuous, innovative user training growing in the future. Attackers and defenders are playing a never-ending game of "cat \& mouse" where nobody can rest.

%AI has empowered attackers to execute highly sophisticated and targeted social engineering attacks, such as spear phishing, vishing (voice phishing) with real-time voice morphing, with truly alarming precision. Sometimes, attacks are augmented with deepfake-generated content. These AI-powered attacks exploit human vulnerabilities more efficiently than ever before, making traditional detection and prevention methods increasingly inadequate.

%%AI's role in augmenting social engineering attacks is most evident in its ability to automate and amplify deceptive practices. Techniques utilizing machine learning allow for the generation of personalized phishing messages that are difficult to distinguish from legitimate communications. Deepfake technologies create convincing synthetic media, including images, audio and even videos, which can be used to deceive targets into divulging sensitive information or performing actions on the attacker's request.

%AI's role in augmenting social engineering attacks is most evident in its ability to automate and amplify deceptive practices. Techniques such as Natural Language Processing (NLP) allow for the generation of personalized phishing messages that are difficult to distinguish from legitimate communications. Deepfake technologies create convincing synthetic media, including images, videos and real-time voice morphing, which can be used to deceive targets into divulging sensitive information or performing actions on the attacker's request.

%Automated open-source intelligence (OSINT) gathering further enchances the attacker's ability to craft belieavable pretexts and scenarios, making their social engineering effors more convincing and harder to detect.



%As we've seen, SE is still as much a threat as it has ever been, despite major efforts to the contrary.



%X in Y references that training users effects will wear off in 3 weeks, necessiting continous retraining approaches.

%I'll end with the question that I started with; what, if anything, can the end-user trust anymore? And perhaps, with the advances in AI technology, the answer is "no-one".


%Modern AI can assist with the deployment of the pretext by being a sparring partner to the attacker, giving a safe "sandbox" to try out potential attacks and find ways in which the target might react.

% calling a CEO to get their voice sample, if not found via OSINT from YouTube or TV news or elsewhere etc