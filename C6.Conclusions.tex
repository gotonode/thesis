

% --------------------------------
% CONCLUSIONS
% --------------------------------


\chapter{Conclusions\label{chapter:conclusions}}

\begin{comment}

Guides:
    - 1 to 3 pages max?
    - No subsections

TODO:
    [ ] How AI has augmented SE attacks and countermeasures
    [ ] Gap in the literature

What to cover:
    - How AI has augmented SE attacks and countermeasures
    - Gap in the literature regarding SE and AI intersection?
    - Analysis on where AI-powered SE attacks might be headed in the future
        - Also about robotics and human-like actors
    - What organizations and individuals need to do regarding the evolving landscape of SE attacks

Speculation:
    - Drones dropping USB thumbdrives?
    - Human-like android as threat actors
    - Impact of robotics on dumpster diving, shoulder surfing and baiting
    
Literature:
    - Gen and detection of deepfakes

From training material:
    - "Yhteenveto vaatimattomimmillaan on vain lyhyt kertaus kirjoituksen keskeisistä asioista. Arvokkaamman yhteenvedon saa aikaan kommentoimalla työn tulosten arvoa, työn liittymistä ympäristöön ja tulevaisuudennäkymiä. Tällaiset arviot huolellisesti perusteltava."
    - "Yhteenvetoluku kuvaa teknisten johtopäätösten tuomaa impaktia"

\end{comment}

The subfield of social engineering within cybersecurity is undergoing a significant transformation with the advent of modern AI \citep{fakhouriAIDrivenSolutionsForSocialEngineeringAttacks2024}. This thesis explored how AI empowers malicious actors and also how current countermeasures need to be updated to reflect this evolving threat landscape.

Modern AI is revolutionizing social engineering attacks, enabling attackers to use sophisticated tactics like spear phishing \citep{basitComprehensiveSurveyAIenabledPhishingAttacks2021}, impersonation with deepfake content \citep{mirskyTheCreationAndDetectionOfDeepfakes2021} and voice phishing (vishing) with real-time voice morphing \citep{doanBTSEAudioDeepfakeDetectiong2023}. These advancements reveal that traditional countermeasures are becoming ever more ineffective, requiring a re-evaluation of current strategies and tactics.

One of the most notable contributions of AI is its ability to automate and enhance deceptive practices. Machine learning facilitates the crafting of personalized phishing messages that closely mimic legitimate communications, while deepfake technologies alter or produce synthetic media that convincingly impersonate authentic images, audio and videos. Such advancements enable attackers to deceive targets more efficiently into disclosing sensitive information or taking actions that compromise security.

AI has potential to increase the scale and reach of social engineering \citep{blauthArtificialIntelligenceCrime2022}

Where previously an employee could authenticate a caller by recognizing their voice, intonations, and accents \citep{mitnickArtDeceptionControlling2003}, today and especially in the near future this will not be enough. User training and awareness programs need to be updated for novel threat of AI in social engineering.

In their article, \cite{guptaFromChatGPTtoThreatGPT2023}, claim that "\textit{through continued efforts and cooperation among various stakeholders, it’s possible to prevent the misuse of AI systems and ensure their continued benefit to society}", but this can only be true if advanced AI systems remain in the hands of their developers and that they retract older versions of their AI systems from use, since the older versions have already been used by malicious actors. And since with social engineering an attacker can ask ChatGPT to roleplay a certain scenario that the attacker will later enact in a live call, misuse of AI systems can never be fully prevented. AI is a tool, and like any tool it can be used for its intended purpose or in ways the original manufacturer did not intend or would not want.

According to IBM's 2024 Cost of a Data Breach\footnote{https://www.ibm.com/reports/data-breach (accessed 2024-08-11)} report, organizations are increasingly leveraging AI and automation in their security operations, with 2/3's of studied organizations deploying these technologies. This presents a 10\% increase from last year. Notably, when AI was extensively deployed in prevention workflows, including attack surface management (ASM), red-teaming and posture management, these organizations saw an average reduction of \$2.2 million breach costs compared to the average of \$4,88 million, a 45\% reduction. IBM found a striking correlation, that the more an organization relied on AI, the lower their average breach costs were.

While AI can help detect social engineering attacks, it does not mitigate the need for user training and awareness programs. Quite the contrary, with AI-powered attacks, the need for awareness and vigilance will likely grow even higher. Chatbots like ChatGPT can be used to develop stronger security guidelines and design more engaging social engineering awareness programs.

Dual use property of AI, software created for defense can also be utilized for offensive purposes \citep{blauthArtificialIntelligenceCrime2022}

What seems certain is that we can count on the rapid development of AI technologies, AI-based social engineering attacks evolving with them, and the need for continuous, innovative user training growing in the future. Attackers and defenders are playing a never-ending game of "cat \& mouse" where nobody can rest.