

\chapter{Conclusions\label{chapter:conclusions}}
\begin{comment}
- Muistuta tutkimuskysymys
- Tärkeimmät tulokset ja perusteet
- Incident costs, numbers = impact
suositukset
- Anakyysia, vertailua, arviointia
- Ei turhia osioita, toistoa
- Puutteita kandissa? Mitä olisi hyvä vielä kertoa?’
- phishing by far the most loss causing cyberattack (fbi)
- calls to verified phone numbers (fbi), not relying on phone numbers on emails
- out of 880,418 fbi 298,878 were phishing 2023 (individuals, not organizations)
- more than half of organizations said they are passing the costs to customers ibm
- cybersecurity teams are constantly understaffed ibm
\end{comment}

The subfield of social engineering within cybersecurity is undergoing a significant transformation with the advent of generative AI~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}. This thesis explored how generative AI empowers threat actors in this space and how current countermeasures in an organizational environment need to be updated to reflect this evolving threat landscape.

Generative AI is revolutionizing social engineering attacks, enabling threat actors to use sophisticated tactics like spear phishing~\citep{basit_Comprehensive_Survey_AI_Phishing_Detection_2021}, impersonation with deepfake content~\citep{mirsky_Creation_Detection_Deepfakes_2021} and voice phishing, vishing, with real-time voice morphing~\citep{doan_BTSE_Audio_Deepfake_Detection_2023}. These advancements reveal that traditional countermeasures are becoming increasingly ineffective, requiring an urgent and comprehensive re-evaluation of current cybersecurity strategies.

Previously an employee could authenticate a caller by recognizing their voice, intonations, and accent~\citep{mitnick_The_Art_of_Deception_2003}, but today this is no longer enough. User training and awareness programs must be updated to address the novel threat of AI in social engineering. Historically, employees have been trained to spot spelling errors in email messages, and today they must be trained to broaden their scope of skepticism to include images, audio, and videos as well~\citep{mirsky_Creation_Detection_Deepfakes_2021}.

AI can help detect social engineering attacks, but it does not eliminate the necessity for user training and awareness programs. On the contrary, as AI-powered attacks proliferate, the need for awareness and vigilance will grow even higher~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}. Chatbots like ChatGPT can help develop more robust security guidelines and design highly engaging social engineering awareness programs. In addition, image-generation technologies like DALL-E can help create memorable and funny images for posters and campaigns.

One area not addressed in this thesis, but deserving of future research, is the potential for AI to automate social engineering attacks, either in part or even completely~\citep{mirsky_Threat_Offensive_AI_Organizations_2023}. Currently, however, AI technology is not capable of executing such attacks without human oversight, but as the field is evolving rapidly, organizations must take this possibility into consideration as well.


%The Cost of a Data Breach Report~\citep{ibm_Cost_Data_Breach_Report_2024} revealed that organizations using AI to address cybersecurity threats experienced an average of 45\% reduction in annual incident-related costs compared to those that did not. Further, IBM found that increased reliance on AI corresponded with lower incident costs. Organizations need to utilize AI to combat generative AI -powered social engineering, primarily because even the best-trained employee could fall victim to a sophisticated spear phishing scheme.



It seems evident that the highly dynamic nature of AI technologies fuels a continuous arms race between threat actors and cybersecurity defenders, causing many countermeasures to become obsolete quickly~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}. Thus, protecting organizations against AI-powered social engineering attacks requires not a single solution but an integrated approach that is baked into the organization's culture, that combines technological defenses, comprehensive and continuous employee education, and robust organizational policies.


According to the Cost of a Data Breach Report~\citep{ibm_Cost_Data_Breach_Report_2024}, focusing on employee training reduced the average cost of a data breach incident the most, by \$258,629. For comparison, focusing on cybersecurity software reduced these costs by \$166,600. Organizations with low levels of employee cybersecurity training experienced an average data breach cost of \$5,1 million, while those with high levels of training had costs of \$4,15 million.

Cybersecurity experts must thus concentrate their efforts on deterring the top threats organizations face from generative AI, namely impersonation with deepfakes and highly targeted, seemingly authentic spear phishing. This effort needs to be enacted primarily by prioritizing employee training and secondarily on the acquisition of new, AI-powered social engineering prevention software.

%
% Defense against AI-powered threats
%
%Defense against AI-enhanced social engineering will thus require a multifaceted approach that combines technological innovation, user education, and a proactive stance and strict enforcement of cybersecurity policy~\citep{blauth_AI_Crime_Overview_Malicious_Use_Abuse_2022}. As the landscape continues to evolve, staying ahead of these threats will necessitate ongoing research and collaboration across the cybersecurity community to develop effective countermeasures and best practices~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}.
