\begin{otherlanguage}{english}
\begin{comment}
- PDF/A
\end{comment}
\begin{abstract}

Social engineering, a subdomain of cybersecurity, is the art and science of manipulating people into divulging confidential information or taking actions that may or may not be in their best interests. Traditionally, social engineering relied heavily on manual labor and human intuition, but with the advent of generative artificial intelligence (AI) technologies such as ChatGPT and hyper-realistic deepfake media forgeries, cybercriminals are able to craft increasingly personalized and effective social engineering campaigns with novel, unexpected twists. Current social engineering prevention strategies need to be urgently updated to reflect this change in the threat landscape. This thesis addresses what changes organizations need to make in order to minimize annual cybercrime-related costs induced by \textit{AI -powered social engineering}.

%This thesis addresses how to protect organizations, both public sector and private, from social engineering attacks that are enhanced by generative AI technologies. To that end, this thesis explores the evolving landscape of AI in social engineering, focusing on attacks such as spear phishing aided by chatbots like ChatGPT and impersonation with hyper-realistic deepfake-generated forgeries. In contrast, the thesis also covers countermeasures against these attacks and discusses issues related to them based on relevant literature. Actualized incidents are briefly examined where appropriate.

%The findings show that generative AI -powered social engineering attacks are more persuasive and effective than traditional methods, while current defenses are increasingly inadequate. This underscores the urgent need for cybersecurity professionals to revise their strategies and tools, with AI contributing to this defensive effort as well.



\end{abstract}
\end{otherlanguage}
