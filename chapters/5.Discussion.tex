
\chapter{Discussion and recommendations\label{chapter:discussion}}
\begin{comment}
- viimeisteltyä kirjakieltä, ei alan slangia. "does not", ei "doesn't"
- tietoturvakoulutus työajalla, EI omalla ajalla
- armeijassa saa vapaata hyvästä suorituksesta ammunnoissa. joku bonus gamifikaation kautta?
- employees can work from home, mention this? extra challenges for cybersecurity
- oman tietoturvatiimin tekemänä tai kolmannen osapuolen palveluna
- post-its and posters will likely be tuned out by the brain eventually. thus they must be kept fresh. luckily DALL-E can easily create such content, as often as needed
- orvot aliluvut merkki jäsentelyongelmasta, orvot luvunalotusrivit pakotetaan muun tekstin kanssa samalle sivulle
- muistuttamalla tärkeimmistä havainnoista luvun lopussa tavoitteeseen suhteutettuna
- Teknisten johtopäätösten tuoma impakti
- muistuttaa mieleen tutkimuskysymyksen, mainitsee tärkeimmät tulokset ja niiden perusteet
- keskittyy impaktiin ja esimerkiksi suosituksiin.
- ei pelkästään summeeraa luku kerrallaan aiempaa tekstiä
- As AI is developed further and the more its availability increases, the risk of malicious or criminal use increases as well
\end{comment}

This chapter discusses the current AI-powered social engineering threat landscape, examining countermeasures and their effectiveness at detecting and preventing social engineering attacks, so that organizations could minimize their annual cybercrime-related costs. After this, Chapter~\ref{chapter:conclusions} concludes the thesis.

%This chapter evaluates current countermeasures and their effectiveness at detecting and preventing social engineering attacks, particularly those enhanced by generative AI technologies. After this, Chapter~\ref{chapter:conclusions} concludes the thesis.

The landscape of cybersecurity is continuously evolving, and traditional countermeasures such as email filtering and user awareness programs, although still crucial, are increasingly insufficient against the sophistication of AI-powered threats~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}. While current countermeasures provide a baseline defense against social engineering attacks, the evaluation in this chapter reveals a critical gap between existing strategies and the rapidly evolving sophistication of generative AI -powered attacks. 


\section{Generative AI and deepfakes}
\begin{comment}
\end{comment}

According to the Cost of a Data Breach Report~\citep{ibm_Cost_Data_Breach_Report_2024}, organizations are increasingly leveraging AI and automation in their security operations. 31\% of the studied organizations deploy these technologies extensively, 36\% reported limited use, and the remaining 33\% reported no use. Notably, when AI was extensively deployed in prevention workflows, organizations saw an average breach cost reduction of 45\% (\$2,2 million compared to the average of \$4,88 million). The key finding of IBM's report is a striking correlation: the more an organization relied on AI, the lower its average breach costs were.



Just as phishing filters are inclined to report false positives~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}, so too are deepfake detection systems~\citep{mirsky_Creation_Detection_Deepfakes_2021}. Filtering legitimate communications out may cause operational disturbances and perhaps lost business engagements.

Technological solutions like phishing detection systems that utilize natural language processing and machine learning show potential in identifying anomalous communications~\citep{basit_Comprehensive_Survey_AI_Phishing_Detection_2021}. However, these systems are being challenged by the ever-improving quality of AI-generated content such as spear phishing messages, which mimic human interaction and presentation with higher and higher fidelity. Similarly, tools designed to detect deepfakes are in their early stages, and face significant hurdles in keeping up with the rapid advancements in AI technologies that create such content~\citep{mirsky_Creation_Detection_Deepfakes_2021}.




Virus detection signatures are developed by their respective companies, and cybersecurity personnel must be trained regularly. However, AI makes a difference here because AI systems can learn from other AI systems. Where one network is the target of a novel type of cybersecurity threat, and once its detected, this AI system can inform other systems in the same "network", thus bolstering defenses on a possibly global scale?

%Spreading information about deepfakes to the public faces the hurdle of the "liar's dividend", a situation where a "liar" discredits a real video claiming it to be a deepfake. The more users are aware of deepfake content and the ability of AI to doctor and create videos, the more skeptical they will be, causing them to question images and videos that are real~\citep{blauth_AI_Crime_Overview_Malicious_Use_Abuse_2022}. Deepfakes may thus erode the public's very trust in multimedia content, and the press in general.

AI excels in detecting subtle patterns and anomalies which might elude more conventional systems \citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}. This capability exceeds mere threat recognition and covers concepts such as anticipation of future potential vulnerabilities based on real-time and also historical data, which helps ensure defensive measures are not just reactive but predictive (proactive).



Building and maintaining guidelines for the ethical use of AI systems has been at the forefront of their development. For instance, OpenAI has made strides in an attempt to prevent the misuse of its AI systems. Despite these efforts, the complete prevention of AI system misuse remains yet elusive, particularly since older versions without the latest restrictions might still be accessible, either directly or via API calls~\citep{gupta_From_ChatGPT_to_ThreatGPT_2023}.

\section{Defending employees}
\begin{comment}
\end{comment}

User-oriented measures remain pivotal in the defense against social engineering. Regular training programs are crucial for equipping end-users with the knowledge to recognize potential threats~\citep{hadnagy_Social_Engineering_The_Science_2018}. This holds true especially because AI technologies are evolving rapidly on both the offensive and defensive sides, leading to a situation where the attackers are one step ahead of the defenders and automated AI-based social engineering detection and prevention systems fail to protect the user~\citep{fakhouri_AI_Driven_Solutions_SE_Attacks_2024}. Thus comprehensive, regular and innovative user training and awareness programs can never be overlooked, as the user remains the weakest link in the cybersecurity chain~\citep{mitnick_The_Art_of_Deception_2003}.

A company culture that is open about sharing if any of its members fall victim to social engineering attacks is more robust due to employees not having to feel shame or hide the fact that they got tricked~\citep{hadnagy_Social_Engineering_The_Science_2018}. This can be reinforced by employees, especially executives, talking openly about times when they fell victim, to what kind of attack and why, and what they did about the incident. It's always better that employees report suspected or actualized social engineering attacks rather than trying to hide them for fear of ridicule or punishment.

The deployment of simulated social engineering campaigns offers substantial insights into employee vulnerability, yet these must be meticulously crafted to avoid adverse impacts on workplace morale~\citep{mitnick_The_Art_of_Deception_2003}. Utilizing natural language processing to craft highly convincing but simulated phishing messages, possibly along with the integration of some open-source intelligence, to be sent to the employees can further aid in the detection of the need for further training.

Feedback from these simulations can significantly aid personnel development. However, employees who fall victim to these simulated attacks should be re-educated rather than punished~\citep{mitnick_The_Art_of_Deception_2003}. Furthermore, it is essential to inform employees in advance that such campaigns may be run occasionally. This approach not only helps keep them vigilant but should also mitigate negative feelings associated with "being tricked" by their own company.

%
% Teenagers, young people and autistic people, susceptibility 
%
Just as people have differing propensities for detecting phishing attempts and noticing subtle anomalies in spelling and grammar~\citep{nicholson_Investigating_Teenagers_Detect_Phishing_2020, neupane_Social_Disorders_Facilitate_SE_2018}, so too are people variously adept at spotting these anomalies in deepfakes. Certain parts of the population, such as teenagers and young people who haven't yet gained enough experience on the Internet, may be more susceptible to social engineering attacks~\citep{nicholson_Investigating_Teenagers_Detect_Phishing_2020}. People on the autism spectrum, often facing challenges in social interaction, may unexpectedly excel at detecting social engineering attacks~\citep{neupane_Social_Disorders_Facilitate_SE_2018}.

It is thus suggested that training efforts, while they must be targeted at everyone, would take into account any potential differences in employee demographics. Chatbots like ChatGPT can help in designing tailored and engaging training content, perhaps even with gamification.


